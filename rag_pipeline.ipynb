{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b406b75-4323-478f-a841-4afd87e9095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "import pymupdf #read pdf\n",
    "from tqdm.auto import tqdm #progress bar\n",
    "import pandas as pd #for analysis on sentences, words and token counts of pages\n",
    "from spacy.lang.en import English #for sentence tokenising\n",
    "from sentence_transformers import util, SentenceTransformer #for embedding text and queries\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from config import num_sentence_chunk_size, embed_model_name, collection_name, pdf_path, initial_page, final_page, top_n_results,llm_model_name,  temperature, max_new_tokens, return_answer_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922080a-0d51-491f-b1bc-3b315d606645",
   "metadata": {},
   "source": [
    "### 1. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21f8d8-d0ea-40d2-aee0-e25a6f483aab",
   "metadata": {},
   "source": [
    "#### 1.1 Select, Read and Pre-Process Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4879563-1c13-41a3-a592-92e58068fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    \"\"\"\n",
    "    Performs formatting operation on text, removes unncessary characters.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Text input to be formatted.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of the text provided.\n",
    "    \"\"\"\n",
    "    clean_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59248fe9-de15-4c1f-a29d-da4c0db955a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption -- 1 token = 4 chars\n",
    "def read_pdf(pdf_path, initial_page, final_page):\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "        initial_page (int): The first page number of the PDF to read\n",
    "        final_page (int): The last page number of the PDF to read\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number,\n",
    "        character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    text_pages = []\n",
    "    for page_number, page in tqdm(enumerate(doc.pages(initial_page,final_page))):\n",
    "        #Iterate over each page in the PDF\n",
    "        #Gets the text in the page and stores various information as dict in a list\n",
    "        text = page.get_text()\n",
    "        text = format_text(text)\n",
    "        text_pages.append({\"page_number\": page_number + 19,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return text_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66fb7ef0-2229-46ba-817c-1a9861c097b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832cfa58077841a48589599e4abfcb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Provide path and page numbers to be extracted\n",
    "# initial_page = 18\n",
    "# final_page = 68\n",
    "# pdf_path = r\"E:\\workstation\\ragQuantiphi\\docs\\ConceptsofBiology.pdf\"\n",
    "pages_and_texts = read_pdf(pdf_path,initial_page,final_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec93ad0-6dbe-477b-9467-34984d234774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 19,\n",
       " 'page_char_count': 1542,\n",
       " 'page_word_count': 255,\n",
       " 'page_sentence_count_raw': 10,\n",
       " 'page_token_count': 385.5,\n",
       " 'text': 'INTRODUCTION CHAPTER 1 Introduction to Biology 1.1 Themes and Concepts of Biology 1.2 The Process of Science Viewed from space, Earth (Figure 1.1) offers few clues about the diversity of life forms that reside there. The first forms of life on Earth are thought to have been microorganisms that existed for billions of years before plants and animals appeared. The mammals, birds, and flowers so familiar to us are all relatively recent, originating 130 to 200 million years ago. Humans have inhabited this planet for only the last 2.5 million years, and only in the last 300,000 years have humans started looking like we do today. 1.1 Themes and Concepts of Biology LEARNING OBJECTIVES By the end of this section, you will be able to: • Identify and describe the properties of life • Describe the levels of organization among living things • List examples of different sub disciplines in biology Biology is the science that studies life. What exactly is life? This may sound like a silly question with an obvious answer, but it is not easy to define life. For example, a branch of biology called virology studies viruses, which exhibit some of the characteristics of living entities but lack others. It turns out that although viruses can attack living organisms, cause diseases, and even reproduce, FIGURE 1.1 This NASA image is a composite of several satellite-based views of Earth. To make the whole-Earth image, NASA scientists combine observations of different parts of the planet. (credit: modification of work by NASA) CHAPTER OUTLINE'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c503554e-18a4-41d5-aafb-1a29dd9acfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1542</td>\n",
       "      <td>255</td>\n",
       "      <td>10</td>\n",
       "      <td>385.50</td>\n",
       "      <td>INTRODUCTION CHAPTER 1 Introduction to Biology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2234</td>\n",
       "      <td>337</td>\n",
       "      <td>16</td>\n",
       "      <td>558.50</td>\n",
       "      <td>they do not meet the criteria that biologists ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>1988</td>\n",
       "      <td>306</td>\n",
       "      <td>16</td>\n",
       "      <td>497.00</td>\n",
       "      <td>FIGURE 1.3 The leaves of this sensitive plant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>2092</td>\n",
       "      <td>309</td>\n",
       "      <td>14</td>\n",
       "      <td>523.00</td>\n",
       "      <td>FIGURE 1.4 Although no two look alike, these k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>1477</td>\n",
       "      <td>234</td>\n",
       "      <td>15</td>\n",
       "      <td>369.25</td>\n",
       "      <td>FIGURE 1.6 A lot of energy is required for a C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0           19             1542              255                       10   \n",
       "1           20             2234              337                       16   \n",
       "2           21             1988              306                       16   \n",
       "3           22             2092              309                       14   \n",
       "4           23             1477              234                       15   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0            385.50  INTRODUCTION CHAPTER 1 Introduction to Biology...  \n",
       "1            558.50  they do not meet the criteria that biologists ...  \n",
       "2            497.00  FIGURE 1.3 The leaves of this sensitive plant ...  \n",
       "3            523.00  FIGURE 1.4 Although no two look alike, these k...  \n",
       "4            369.25  FIGURE 1.6 A lot of energy is required for a C...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c14dabc-6e7c-40eb-beb8-6bbf3cebb720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.50000</td>\n",
       "      <td>2630.720000</td>\n",
       "      <td>420.78000</td>\n",
       "      <td>22.960000</td>\n",
       "      <td>657.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.57738</td>\n",
       "      <td>1067.538998</td>\n",
       "      <td>173.98373</td>\n",
       "      <td>12.610265</td>\n",
       "      <td>266.884749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.00000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.25000</td>\n",
       "      <td>1969.250000</td>\n",
       "      <td>303.00000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>492.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.50000</td>\n",
       "      <td>2813.000000</td>\n",
       "      <td>454.50000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>703.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.75000</td>\n",
       "      <td>3359.250000</td>\n",
       "      <td>550.75000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>839.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.00000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>725.00000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count     50.00000        50.000000         50.00000                50.000000   \n",
       "mean      43.50000      2630.720000        420.78000                22.960000   \n",
       "std       14.57738      1067.538998        173.98373                12.610265   \n",
       "min       19.00000       213.000000         41.00000                 1.000000   \n",
       "25%       31.25000      1969.250000        303.00000                15.250000   \n",
       "50%       43.50000      2813.000000        454.50000                22.000000   \n",
       "75%       55.75000      3359.250000        550.75000                28.000000   \n",
       "max       68.00000      4428.000000        725.00000                65.000000   \n",
       "\n",
       "       page_token_count  \n",
       "count         50.000000  \n",
       "mean         657.680000  \n",
       "std          266.884749  \n",
       "min           53.250000  \n",
       "25%          492.312500  \n",
       "50%          703.250000  \n",
       "75%          839.812500  \n",
       "max         1107.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb96048d-c733-4174-b867-2e7e09bd006c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x11ee4357dd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English()\n",
    "# Add a sentencizer pipeline\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "369fde35-f58e-488f-8443-a1067035814d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee25e28a0324fdfa8a4b7f372471004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d1d96f-147e-49f1-8b97-e55e105bb605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.50</td>\n",
       "      <td>2630.72</td>\n",
       "      <td>420.78</td>\n",
       "      <td>22.96</td>\n",
       "      <td>657.68</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.58</td>\n",
       "      <td>1067.54</td>\n",
       "      <td>173.98</td>\n",
       "      <td>12.61</td>\n",
       "      <td>266.88</td>\n",
       "      <td>10.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.00</td>\n",
       "      <td>213.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>53.25</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.25</td>\n",
       "      <td>1969.25</td>\n",
       "      <td>303.00</td>\n",
       "      <td>15.25</td>\n",
       "      <td>492.31</td>\n",
       "      <td>15.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.50</td>\n",
       "      <td>2813.00</td>\n",
       "      <td>454.50</td>\n",
       "      <td>22.00</td>\n",
       "      <td>703.25</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.75</td>\n",
       "      <td>3359.25</td>\n",
       "      <td>550.75</td>\n",
       "      <td>28.00</td>\n",
       "      <td>839.81</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.00</td>\n",
       "      <td>4428.00</td>\n",
       "      <td>725.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>47.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        50.00            50.00            50.00                    50.00   \n",
       "mean         43.50          2630.72           420.78                    22.96   \n",
       "std          14.58          1067.54           173.98                    12.61   \n",
       "min          19.00           213.00            41.00                     1.00   \n",
       "25%          31.25          1969.25           303.00                    15.25   \n",
       "50%          43.50          2813.00           454.50                    22.00   \n",
       "75%          55.75          3359.25           550.75                    28.00   \n",
       "max          68.00          4428.00           725.00                    65.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count             50.00                      50.00  \n",
       "mean             657.68                      22.38  \n",
       "std              266.88                      10.46  \n",
       "min               53.25                       1.00  \n",
       "25%              492.31                      15.25  \n",
       "50%              703.25                      22.00  \n",
       "75%              839.81                      28.00  \n",
       "max             1107.00                      47.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfd5682-8c39-45f7-9f97-00311c53edc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f731beb8146feb430b201d9ef00da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 5 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list, slice_size):\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size.\n",
    "\n",
    "    Parameters:\n",
    "    input_list (list): Input list to slice into sublists\n",
    "    slice_size (int): Input slicing size\n",
    "\n",
    "    Return:\n",
    "    list[list[str]]: List of subsets of the complete input list\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fb2d2cc-b122-4a03-9ef2-9f491d00ebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.50</td>\n",
       "      <td>2630.72</td>\n",
       "      <td>420.78</td>\n",
       "      <td>22.96</td>\n",
       "      <td>657.68</td>\n",
       "      <td>22.38</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.58</td>\n",
       "      <td>1067.54</td>\n",
       "      <td>173.98</td>\n",
       "      <td>12.61</td>\n",
       "      <td>266.88</td>\n",
       "      <td>10.46</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.00</td>\n",
       "      <td>213.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>53.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.25</td>\n",
       "      <td>1969.25</td>\n",
       "      <td>303.00</td>\n",
       "      <td>15.25</td>\n",
       "      <td>492.31</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.50</td>\n",
       "      <td>2813.00</td>\n",
       "      <td>454.50</td>\n",
       "      <td>22.00</td>\n",
       "      <td>703.25</td>\n",
       "      <td>22.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.75</td>\n",
       "      <td>3359.25</td>\n",
       "      <td>550.75</td>\n",
       "      <td>28.00</td>\n",
       "      <td>839.81</td>\n",
       "      <td>28.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.00</td>\n",
       "      <td>4428.00</td>\n",
       "      <td>725.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        50.00            50.00            50.00                    50.00   \n",
       "mean         43.50          2630.72           420.78                    22.96   \n",
       "std          14.58          1067.54           173.98                    12.61   \n",
       "min          19.00           213.00            41.00                     1.00   \n",
       "25%          31.25          1969.25           303.00                    15.25   \n",
       "50%          43.50          2813.00           454.50                    22.00   \n",
       "75%          55.75          3359.25           550.75                    28.00   \n",
       "max          68.00          4428.00           725.00                    65.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count             50.00                      50.00       50.00  \n",
       "mean             657.68                      22.38        4.82  \n",
       "std              266.88                      10.46        2.11  \n",
       "min               53.25                       1.00        1.00  \n",
       "25%              492.31                      15.25        3.25  \n",
       "50%              703.25                      22.00        5.00  \n",
       "75%              839.81                      28.00        6.00  \n",
       "max             1107.00                      47.00       10.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1247f334-ac43-4472-8533-fe33a540ad2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40b6bc990ef4d78ad421632a15d8091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        #joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo  #delete\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2d55018-35b0-4bdc-9f55-c0cb040acc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 19,\n",
       " 'sentence_chunk': 'INTRODUCTION CHAPTER 1 Introduction to Biology 1.1 Themes and Concepts of Biology 1.2 The Process of Science Viewed from space, Earth (Figure 1.1) offers few clues about the diversity of life forms that reside there.The first forms of life on Earth are thought to have been microorganisms that existed for billions of years before plants and animals appeared.The mammals, birds, and flowers so familiar to us are all relatively recent, originating 130 to 200 million years ago.Humans have inhabited this planet for only the last 2.5 million years, and only in the last 300,000 years have humans started looking like we do today.1.1 Themes and Concepts of Biology LEARNING OBJECTIVES By the end of this section, you will be able to: • Identify and describe the properties of life • Describe the levels of organization among living things • List examples of different sub disciplines in biology Biology is the science that studies life.',\n",
       " 'chunk_char_count': 934,\n",
       " 'chunk_word_count': 154,\n",
       " 'chunk_token_count': 233.5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8ec5b3-fe25-4bb3-a199-676fda9cbfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>241.00</td>\n",
       "      <td>241.00</td>\n",
       "      <td>241.00</td>\n",
       "      <td>241.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.33</td>\n",
       "      <td>541.49</td>\n",
       "      <td>83.78</td>\n",
       "      <td>135.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.71</td>\n",
       "      <td>410.55</td>\n",
       "      <td>64.49</td>\n",
       "      <td>102.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.00</td>\n",
       "      <td>387.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>96.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.00</td>\n",
       "      <td>524.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>131.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.00</td>\n",
       "      <td>633.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>158.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.00</td>\n",
       "      <td>4354.00</td>\n",
       "      <td>705.00</td>\n",
       "      <td>1088.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count       241.00            241.00            241.00             241.00\n",
       "mean         44.33            541.49             83.78             135.37\n",
       "std          13.71            410.55             64.49             102.64\n",
       "min          19.00             38.00              8.00               9.50\n",
       "25%          33.00            387.00             60.00              96.75\n",
       "50%          45.00            524.00             80.00             131.00\n",
       "75%          56.00            633.00             98.00             158.25\n",
       "max          68.00           4354.00            705.00            1088.50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1ef657-bc38-4a5e-ba31-6a2d386b4a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>30</td>\n",
       "      <td>These cells have contributed to major medical ...</td>\n",
       "      <td>1247</td>\n",
       "      <td>199</td>\n",
       "      <td>311.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>38</td>\n",
       "      <td>Key Terms applied science a form of science th...</td>\n",
       "      <td>3867</td>\n",
       "      <td>578</td>\n",
       "      <td>966.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>65</td>\n",
       "      <td>Key Terms acid a substance that donates hydrog...</td>\n",
       "      <td>4354</td>\n",
       "      <td>705</td>\n",
       "      <td>1088.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>66</td>\n",
       "      <td>electrons oil an unsaturated fat that is a liq...</td>\n",
       "      <td>2851</td>\n",
       "      <td>455</td>\n",
       "      <td>712.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number                                     sentence_chunk  \\\n",
       "45            30  These cells have contributed to major medical ...   \n",
       "87            38  Key Terms applied science a form of science th...   \n",
       "223           65  Key Terms acid a substance that donates hydrog...   \n",
       "224           66  electrons oil an unsaturated fat that is a liq...   \n",
       "\n",
       "     chunk_char_count  chunk_word_count  chunk_token_count  \n",
       "45               1247               199             311.75  \n",
       "87               3867               578             966.75  \n",
       "223              4354               705            1088.50  \n",
       "224              2851               455             712.75  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['chunk_token_count'] > 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429c1ec-d9e8-4746-845e-678929c50427",
   "metadata": {},
   "source": [
    "#### 1.2 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a4e480-1571-4229-b7a2-b30efa296319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embedding_model = SentenceTransformer(model_name_or_path=embed_model_name, \n",
    "                                      device=device)\n",
    "embedding_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3e9ed4-5c16-4d7b-81d4-618503dc0316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 19,\n",
       " 'sentence_chunk': 'INTRODUCTION CHAPTER 1 Introduction to Biology 1.1 Themes and Concepts of Biology 1.2 The Process of Science Viewed from space, Earth (Figure 1.1) offers few clues about the diversity of life forms that reside there.The first forms of life on Earth are thought to have been microorganisms that existed for billions of years before plants and animals appeared.The mammals, birds, and flowers so familiar to us are all relatively recent, originating 130 to 200 million years ago.Humans have inhabited this planet for only the last 2.5 million years, and only in the last 300,000 years have humans started looking like we do today.1.1 Themes and Concepts of Biology LEARNING OBJECTIVES By the end of this section, you will be able to: • Identify and describe the properties of life • Describe the levels of organization among living things • List examples of different sub disciplines in biology Biology is the science that studies life.',\n",
       " 'chunk_char_count': 934,\n",
       " 'chunk_word_count': 154,\n",
       " 'chunk_token_count': 233.5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6aade4-48d4-4a81-969a-edac559cf15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8f420cb3cf41c18b5e9bb65c1271b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_chunks):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3b85ea7-47c4-4232-beb2-f00e5e1df3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn text chunks into a single list\n",
    "#text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a80a7da-56a3-4746-87fa-39ec3dc2fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Embed all texts in batches\n",
    "# text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "#                                                batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "#                                                convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "# text_chunk_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0d602f-33bf-4f19-a1a5-54ea70042e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70ff5318-b4d9-4258-948b-49fef0ec7316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>INTRODUCTION CHAPTER 1 Introduction to Biology...</td>\n",
       "      <td>934</td>\n",
       "      <td>154</td>\n",
       "      <td>233.50</td>\n",
       "      <td>[ 2.10180786e-02 -6.17712848e-02 -7.68414419e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>What exactly is life?This may sound like a sil...</td>\n",
       "      <td>546</td>\n",
       "      <td>86</td>\n",
       "      <td>136.50</td>\n",
       "      <td>[ 3.66447382e-02 -8.72069001e-02  1.25827771e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>credit: modification of work by NASA) CHAPTER ...</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>13.25</td>\n",
       "      <td>[ 6.44325837e-02 -3.99337001e-02 -4.67345759e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>they do not meet the criteria that biologists ...</td>\n",
       "      <td>493</td>\n",
       "      <td>74</td>\n",
       "      <td>123.25</td>\n",
       "      <td>[ 1.34523567e-02 -5.14974296e-02  6.96373824e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>As new organisms are discovered every day, bio...</td>\n",
       "      <td>574</td>\n",
       "      <td>74</td>\n",
       "      <td>143.50</td>\n",
       "      <td>[-2.09128428e-02  2.58600269e-03 -6.61942270e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0           19  INTRODUCTION CHAPTER 1 Introduction to Biology...   \n",
       "1           19  What exactly is life?This may sound like a sil...   \n",
       "2           19  credit: modification of work by NASA) CHAPTER ...   \n",
       "3           20  they do not meet the criteria that biologists ...   \n",
       "4           20  As new organisms are discovered every day, bio...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               934               154             233.50   \n",
       "1               546                86             136.50   \n",
       "2                53                 8              13.25   \n",
       "3               493                74             123.25   \n",
       "4               574                74             143.50   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 2.10180786e-02 -6.17712848e-02 -7.68414419e-...  \n",
       "1  [ 3.66447382e-02 -8.72069001e-02  1.25827771e-...  \n",
       "2  [ 6.44325837e-02 -3.99337001e-02 -4.67345759e-...  \n",
       "3  [ 1.34523567e-02 -5.14974296e-02  6.96373824e-...  \n",
       "4  [-2.09128428e-02  2.58600269e-03 -6.61942270e-...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b46063c3-5808-4438-8f74-4b15848c4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f59be0e3-dca2-49d7-8886-81bfbc37a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe220d1-1af9-4dd8-8b7b-e30d8ee209e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65df52ff-3de3-4bc8-b0b1-d4019886057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query, embeddings, model=embedding_model, n_resources_to_return=5):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): User input query\n",
    "    embeddings (torch.Tensor): Embeddings of text chunks\n",
    "    model (SentenceTransformer): Sentence Transformer model to use\n",
    "    n_resources_to_return (int): No. of results to return\n",
    "\n",
    "    Return:\n",
    "    list[float]: list of top scores\n",
    "    list[int]: list of index of top scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdde5a6d-6306-4073-a2c8-6ed80b49e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7186, 0.6939, 0.6394, 0.6321, 0.5974], device='cuda:0'),\n",
       " tensor([48, 89, 46, 47, 38], device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Biology?\"\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bb563f7-3b6a-4377-a3dc-7cdb10c87b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17fc50116024969b938d21df49e112c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name,trust_remote_code=True)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name,torch_dtype=torch.bfloat16, device_map=\"auto\",quantization_config=quantization_config, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ccbbed8-0dd3-4558-84be-ed5db6d8017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query, context_items):\n",
    "    \"\"\"\n",
    "    Combines query and context from retrieval method\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The user query\n",
    "    context_items (list[dict]): The context from retrieval method, top n answers\n",
    "\n",
    "    Returns:\n",
    "    str: Prompt for LLM model\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the context passages provided, answer the query.\n",
    "\n",
    "Answer generation must follow below instructions:\n",
    "1. Generate the answer by extracting relevant information from the context.\n",
    "2. Don't return the thinking, only return the answer.\n",
    "3. Make sure your answers are as explanatory as possible.\n",
    "\n",
    "Now use the following context items to answer the user query:\n",
    "{context}\n",
    "\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an helful assistant to answer queries by finding information in few given passages. Answer the given query by going through passages or context items provided.\"},\n",
    "        {\"role\": \"user\", \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db5a9f93-3358-4e1e-9936-c63b03eb82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "    \n",
    "    # Create a list of context items\n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(model_inputs.input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    output_answer = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, outputs)]\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    response = tokenizer.batch_decode(output_answer, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return response\n",
    "    \n",
    "    return response, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3121fe48-3558-4be6-ba10-c77a2cf7f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Biology?\n",
      "Answer:\n",
      "\n",
      "Biology is the study of life. It is a science that gathers knowledge about the natural world, specifically focusing on the discoveries of life forms and their interactions. Biology, like all sciences, is a social enterprise that requires careful observation, logical reasoning, experimentation, and sharing of conclusions under the scrutiny of others. It encompasses various fields, such as physiology, which studies the workings of cells, tissues, and organs. Biology's discoveries have significant practical implications affecting our health, food sources, and benefits from our ecosystem.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context \n",
    "answer, context_items = ask(query=query, \n",
    "                            temperature=temperature,\n",
    "                            max_new_tokens=max_new_tokens,\n",
    "                            return_answer_only=False)\n",
    "\n",
    "print(f\"Answer:\\n\")\n",
    "print(answer)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9bbd77b-d853-47a2-91ea-9d1d1f1e9073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'What is Biology?'\n",
      "\n",
      "Results:\n",
      "Score: 0.7186\n",
      "Text:\n",
      "Whatever its goal, there is no doubt that science, including biology, has transformed human existence and will continue to do so.FIGURE 1.15 Biologists may choose to study Escherichia coli (E. coli), a bacterium that is a normal resident of our digestive tracts but which is also sometimes responsible for disease outbreaks.In this micrograph, the bacterium is visualized using a scanning electron microscope and digital colorization. (credit: Eric Erbe; digital colorization by Christopher Pooley, USDA-ARS) The Nature of Science Biology is a science, but what exactly is science?What does the study of biology share with other scientific disciplines?\n",
      "Page number: 31\n",
      "\n",
      "\n",
      "Score: 0.6939\n",
      "Text:\n",
      "1.2 The Process of Science Biology is the science that studies living organisms and their interactions with one another and their environments.Science attempts to describe and understand the nature of the universe in whole or in part.Science has many fields; those fields related to the physical world and its phenomena are considered natural sciences.A hypothesis is a tentative explanation for an observation.A generally accepted scientific theory is thoroughly tested and confirmed explanation for a set of observations or phenomena.\n",
      "Page number: 39\n",
      "\n",
      "\n",
      "Score: 0.6394\n",
      "Text:\n",
      "FIGURE 1.14 Formerly called blue-green algae, the (a) cyanobacteria seen through a light microscope are some of Earth’s oldest life forms.These (b) stromatolites along the shores of Lake Thetis in Western Australia are ancient structures formed by the layering of cyanobacteria in shallow waters. (credit a: modification of work by NASA; scale-bar data from Matt Russell; credit b: modification of work by Ruth Ellison) Like geology, physics, and chemistry, biology is a science that gathers knowledge about the natural world.Specifically, biology is the study of life.The discoveries of biology are made by a community of researchers who work individually and together using agreed-on methods.\n",
      "Page number: 31\n",
      "\n",
      "\n",
      "Score: 0.6321\n",
      "Text:\n",
      "In this sense, biology, like all sciences is a social enterprise like politics or the arts.The methods of science include careful observation, record keeping, logical and mathematical reasoning, experimentation, and submitting conclusions to the scrutiny of others.Science also requires considerable imagination and creativity; a well-designed experiment is commonly described as elegant, or beautiful.Like politics, science has considerable practical implications and some science is dedicated to practical applications, such as the prevention of disease (see Figure 1.15).Other science proceeds largely motivated by curiosity.\n",
      "Page number: 31\n",
      "\n",
      "\n",
      "Score: 0.5974\n",
      "Text:\n",
      "Physiologists study the workings of cells, tissues and organs.This is just a small sample of the many fields that biologists can pursue.From our own bodies to the world we live in, discoveries in biology can affect us in very direct and important ways.We depend on these discoveries for our health, our food sources, and the benefits provided by our ecosystem.Because of this, knowledge of biology can benefit us in making decisions in our day-to-day lives.\n",
      "Page number: 29\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(scores, indices):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    # Print the page number too so we can reference the textbook further (and check the results)\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c84bba-9dc4-425a-bd96-d69d071b0491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
